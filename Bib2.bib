
@article{desai_epistemological_2022,
	title = {The epistemological foundations of data science: a critical review},
	volume = {200},
	issn = {1573-0964},
	shorttitle = {The epistemological foundations of data science},
	url = {https://link.springer.com/10.1007/s11229-022-03933-2},
	doi = {10.1007/s11229-022-03933-2},
	abstract = {Abstract
            The modern abundance and prominence of data have led to the development of “data science” as a new field of enquiry, along with a body of epistemological reflections upon its foundations, methods, and consequences. This article provides a systematic analysis and critical review of significant open problems and debates in the epistemology of data science. We propose a partition of the epistemology of data science into the following five domains: (i) the constitution of data science; (ii) the kind of enquiry that it identifies; (iii) the kinds of knowledge that data science generates; (iv) the nature and epistemological significance of “black box” problems; and (v) the relationship between data science and the philosophy of science more generally.},
	language = {en},
	number = {6},
	urldate = {2023-11-03},
	journal = {Synthese},
	author = {Desai, Jules and Watson, David and Wang, Vincent and Taddeo, Mariarosaria and Floridi, Luciano},
	month = nov,
	year = {2022},
	pages = {469},
	file = {Полный текст:C\:\\Users\\User\\Zotero\\storage\\WCQ324J9\\Desai и др. - 2022 - The epistemological foundations of data science a.pdf:application/pdf},
}

@article{symons_can_2016,
	title = {Can we trust {Big} {Data}? {Applying} philosophy of science to software},
	volume = {3},
	issn = {2053-9517, 2053-9517},
	shorttitle = {Can we trust {Big} {Data}?},
	url = {http://journals.sagepub.com/doi/10.1177/2053951716664747},
	doi = {10.1177/2053951716664747},
	abstract = {We address some of the epistemological challenges highlighted by the Critical Data Studies literature by reference to some of the key debates in the philosophy of science concerning computational modeling and simulation. We provide a brief overview of these debates focusing particularly on what Paul Humphreys calls epistemic opacity. We argue that debates in Critical Data Studies and philosophy of science have neglected the problem of error management and error detection. This is an especially important feature of the epistemology of Big Data. In “Error” section we explain the main characteristics of error detection and correction along with the relationship between error and path complexity in software. In this section we provide an overview of conventional statistical methods for error detection and review their limitations when faced with the high degree of conditionality inherent to modern software systems.},
	language = {en},
	number = {2},
	urldate = {2023-11-03},
	journal = {Big Data \& Society},
	author = {Symons, John and Alvarado, Ramón},
	month = dec,
	year = {2016},
	pages = {205395171666474},
	file = {Полный текст:C\:\\Users\\User\\Zotero\\storage\\V7LH483I\\Symons и Alvarado - 2016 - Can we trust Big Data Applying philosophy of scie.pdf:application/pdf},
}

@article{symons_epistemic_2019,
	title = {Epistemic {Entitlements} and the {Practice} of {Computer} {Simulation}},
	volume = {29},
	issn = {0924-6495, 1572-8641},
	url = {http://link.springer.com/10.1007/s11023-018-9487-0},
	doi = {10.1007/s11023-018-9487-0},
	language = {en},
	number = {1},
	urldate = {2023-11-03},
	journal = {Minds and Machines},
	author = {Symons, John and Alvarado, Ramón},
	month = mar,
	year = {2019},
	pages = {37--60},
}

@article{tsamados_ethics_2020,
	title = {The {Ethics} of {Algorithms}: {Key} {Problems} and {Solutions}},
	issn = {1556-5068},
	shorttitle = {The {Ethics} of {Algorithms}},
	url = {https://www.ssrn.com/abstract=3662302},
	doi = {10.2139/ssrn.3662302},
	language = {en},
	urldate = {2023-11-03},
	journal = {SSRN Electronic Journal},
	author = {Tsamados, Andreas and Aggarwal, Nikita and Cowls, Josh and Morley, Jessica and Roberts, Huw and Taddeo, Mariarosaria and Floridi, Luciano},
	year = {2020},
	file = {Отправленная версия:C\:\\Users\\User\\Zotero\\storage\\K98ML364\\Tsamados и др. - 2020 - The Ethics of Algorithms Key Problems and Solutio.pdf:application/pdf},
}

@book{wolfram_new_2019,
	address = {Champaign, IL},
	title = {A new kind of science},
	isbn = {978-1-57955-025-7},
	language = {eng},
	publisher = {Wolfram Media},
	author = {Wolfram, Stephen},
	year = {2019},
}

@misc{todd_computation_2023,
	title = {"{Computation}." {From} {MathWorld}--{A} {Wolfram} {Web} {Resource}, created by {Eric} {W}. {Weisstein}.},
	url = {https://mathworld.wolfram.com/Computation.html},
	author = {Todd, Rowald},
	year = {2023},
}

@book{__1994,
	address = {Москва},
	title = {Вычислимость и логика},
	publisher = {Мир},
	author = {Булос, Дж. and Джеффри, Р.},
	year = {1994},
	file = {fa01837.djvu:C\:\\Users\\User\\Zotero\\storage\\GI6YWILK\\fa01837.djvu:application/octet-stream},
}

@misc{noauthor_123_nodate,
	title = {123 задачи с {IT}-собеседований — вопросы и логические задачи с решением и ответами},
	url = {https://workspace.ru/blog/123-zadachi-s-it-sobesedovaniy-s-razborom-resheniy/},
	abstract = {О чем спрашивают на собеседовании IT-компаний? Самые популярные логические задачи для программистов с IT-собеседований — решение, логика, ответы.  Более 100 логических задач и вопросов с IT-собеседований.},
	language = {ru},
	urldate = {2023-11-18},
	journal = {WORKSPACE},
	annote = {Классическая задачка с собеседований в Google. На доске записаны числа, вам нужно ответить на вопрос: какое число идёт дальше?

Свернуть
Чаще всего все пытаются отыскать – безуспешно – какую-либо закономерность в серии чисел, которая кажется совершенно бессмысленной. Но здесь нужно забыть математику. Произнесите эти числа на английском (см. рисунок), окажется, что они расположены в порядке возрастания числа букв, содержащихся в их написании.

Теперь приглядитесь еще более внимательно к этой серии. 10 – не единственное число из трёх букв. На этом месте могло бы быть 1, 2 и 6 (one, two и six). То же можно сказать и про 9, подойдут 0, 4 и 5 (zero, four и five). Таким образом можно сделать вывод, что в список включены самые крупные числа из тех, что можно выразить словами с заданным числом букв.
Так какой будет правильный ответ? Очевидно, что в числе, следующем за 66, должно быть девять букв (не считая возможного дефиса), и оно должно быть самым крупным в своём роде. Немного подумав, можно сказать, что ответ будет 96 (ninety-six). Вы понимаете, что сюда не подходят числа, превышающие 100, поскольку для «one hundred» уже нужно десять букв.
Может быть, у вас возникнет вопрос, почему в приведённом списке на месте 70 не стоит сто (hundred), или миллион, или миллиард, для написания которых также нужно семь букв. Скорее всего потому, что на правильном английском языке говорится не «сто», а «одна сотня», то же относится и к двум другим случаям.
Казалось бы, всё, вот он правильный ответ. В Google его считают приемлемым, но не самым совершенным. Есть число побольше:
10 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000,
которое записывается как «one googol» (девять букв).
Однако и это еще не самый лучший вариант. Идеальный ответ: «ten googol», десять гуголов.
Хотите узнать историю этого ответа? Погуглите;)
},
	file = {Snapshot:C\:\\Users\\User\\Zotero\\storage\\M4WNL42E\\123-zadachi-s-it-sobesedovaniy-s-razborom-resheniy.html:text/html},
}

@book{__1986,
	address = {М.},
	title = {Обобщения чисел},
	url = {https://www.mathedu.ru/text/pontryagin_obobshheniya_chisel_1986/},
	abstract = {Понтрягин Л. С. Обобщения чисел. — М. : Наука, 1986. — 120 с. — (Библиотечка «Квант» ; вып. 54).},
	language = {ru},
	urldate = {2023-11-18},
	publisher = {Наука},
	author = {Понтрягин, Л. С.},
	year = {1986},
	file = {Snapshot:C\:\\Users\\User\\Zotero\\storage\\WNQFHA8Q\\p4.html:text/html},
}

@book{__2005,
	address = {М.},
	title = {Введение в системы баз данных},
	isbn = {5-8459-0788-8},
	publisher = {Издательский дом "Вильяме"},
	author = {Дейт, К. Дж.},
	year = {2005},
	file = {Дейт - 2005 - Введение в системы баз данных.pdf:C\:\\Users\\User\\Zotero\\storage\\JI8XI84X\\Дейт - 2005 - Введение в системы баз данных.pdf:application/pdf},
}

@article{national_research_lobachevsky_state_university_of_nizhny_novgorod_postulates_2022,
	title = {Postulates of the cognitive theory of thinking and their consequences},
	volume = {30},
	issn = {08696632, 25421905},
	url = {https://andjournal.sgu.ru/en/articles/postulates-of-the-cognitive-theory-of-thinking-and-their-consequences},
	doi = {10.18500/0869-6632-2022-30-4-480-494},
	abstract = {Purpose of the work is to create a theoretical model of the thinking process, considered as a set of operations for the formation of cognitive generalizations of the level of categories (concepts). Method for creating a theoretical model is based on the approach used in natural sciences. It involves the selection of a small number of reliable facts, which are accepted as true on the basis of their evidence. On the basis of these facts, established in various scientific disciplines, the axioms of the proposed theory are formulated. Further, from the accepted axioms, they are logically deduced in the form of consequences: a) already known results that could be obtained in various fields of science, including those differing in the content of research, and therefore previously perceived as not related to each other; b) predictions of new connections and patterns in the study area. Results of the work are that it was possible to propose a version of the postulate dynamic theory of thinking, in which the main variables are the number of concepts formed, lost, realized and unconscious by the subject. The introduced postulates and variables made it possible to consider two types of models at the moment. Balanced integrodifferential models that describe the accumulation of the volume of conscious and unconscious concepts, as well as combinatorial models that describe the interactions of concepts. Conclusion. The proposed version of the dynamic thinking model made it possible to construct reasonable theoretical descriptions of the process of spontaneous language acquisition by bilingual children in a bilingual environment and a person’s ability to compare semantically heterogeneous objects with each other. The logical scheme of the approach and the concepts used in it made it possible to connect some facts known in psychology and in an explicitly compact formulation of the difference in the structure of scientific and artistic generalizations of the picture of the world.},
	number = {4},
	urldate = {2023-11-22},
	journal = {Izvestiya VUZ. Applied Nonlinear Dynamics},
	author = {{National Research Lobachevsky State University of Nizhny Novgorod} and Antonets, Vladimir},
	month = aug,
	year = {2022},
	pages = {480--494},
	file = {Полный текст:C\:\\Users\\User\\Zotero\\storage\\RFDVTCVF\\National Research Lobachevsky State University of Nizhny Novgorod и Antonets - 2022 - Postulates of the cognitive theory of thinking and.pdf:application/pdf},
}

@article{battista_capacity-resolution_2020,
	title = {Capacity-{Resolution} {Trade}-{Off} in the {Optimal} {Learning} of {Multiple} {Low}-{Dimensional} {Manifolds} by {Attractor} {Neural} {Networks}},
	volume = {124},
	issn = {0031-9007, 1079-7114},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.124.048302},
	doi = {10.1103/PhysRevLett.124.048302},
	language = {en},
	number = {4},
	urldate = {2023-11-22},
	journal = {Physical Review Letters},
	author = {Battista, Aldo and Monasson, Rémi},
	month = jan,
	year = {2020},
	pages = {048302},
	file = {Отправленная версия:C\:\\Users\\User\\Zotero\\storage\\R6HEBZFC\\Battista и Monasson - 2020 - Capacity-Resolution Trade-Off in the Optimal Learn.pdf:application/pdf;Отправленная версия:C\:\\Users\\User\\Zotero\\storage\\N2IH2SDS\\Battista и Monasson - 2020 - Capacity-Resolution Trade-Off in the Optimal Learn.pdf:application/pdf},
}

@book{__2020,
	address = {М.},
	edition = {Канон + РООИ "Реабилитация"},
	series = {Библиотека аналитической философии},
	title = {Почему вообще существует философия  математики?},
	author = {Хакинг, Ян},
	year = {2020},
}

@article{__2021,
	title = {Компьютер как новая реальность математики. {IV}. Проблема Гольдбаха},
	issn = {20712340, 20712359},
	url = {http://cte.eltech.ru/ojs/index.php/kio/article/view/1699},
	doi = {10.32603/2071-2340-2021-4-5-71},
	abstract = {В этой части я продолжаю обсуждать роль компьютера в современных исследованиях по аддитивной теории чисел. Здесь будет рассказано об окончательном решении тернарной = нечетной проблемы Гольбаха не в асимптотических переформулировках XX века, а в исходной формулировке XVIII века. Речь идет об утверждении, что каждое нечетное натуральное число n {\textgreater} 5 можно представить как сумму n = p1 +p2 +p3 трех натуральных простых. Решение этой проблемы было завершено только Харальдом Хельфготтом в 2013–2014 годах и не могло бы быть получено без использования компьютеров. В настоящей статье задокументирована история этой классической задачи и ее решения, в частности, указывается на огромное количество имеющихся в литературе исторических ошибок. Кроме того, обсуждаются статус бинарной = четной проблемы Гольдбаха, частичные результаты в направлении ее решения и некоторые близкие задачи.},
	number = {4},
	urldate = {2023-12-16},
	journal = {Компьютерные инструменты в образовании},
	author = {Вавилов, Н.А.},
	month = dec,
	year = {2021},
	pages = {5--71},
	file = {Полный текст:C\:\\Users\\User\\Zotero\\storage\\AIDBZ849\\Saint Petersburg State University, 29, Line 14th, Vasilyevsky Island, 199178, Saint Petersburg, Russia и Vavilov - 2021 - Computers as Novel Mathematical Reality. IV. Goldb.pdf:application/pdf},
}

@misc{__2011,
	title = {Что нужно знать про арифметику с плавающей запятой},
	url = {https://habr.com/ru/articles/112953/},
	author = {Ющенко, Руслан},
	year = {2011},
}

@book{gromov_great_2018,
	address = {Cham},
	title = {Great {Circle} of {Mysteries}: {Mathematics}, the {World}, the {Mind}},
	isbn = {978-3-319-53048-2 978-3-319-53049-9},
	shorttitle = {Great {Circle} of {Mysteries}},
	language = {en},
	urldate = {2023-12-16},
	publisher = {Springer International Publishing},
	author = {Gromov, Misha},
	year = {2018},
	doi = {10.1007/978-3-319-53049-9},
	file = {Gromov - 2018 - Great Circle of Mysteries Mathematics, the World,.pdf:C\:\\Users\\User\\Zotero\\storage\\92P4S7CL\\Gromov - 2018 - Great Circle of Mysteries Mathematics, the World,.pdf:application/pdf;Misha Gromov - Great Circle of Mysteries. Mathematics, the World, the Mind-Birkhäuser (2017)(Z-Lib.io).pdf:C\:\\Users\\User\\Downloads\\Misha Gromov - Great Circle of Mysteries. Mathematics, the World, the Mind-Birkhäuser (2017)(Z-Lib.io).pdf:application/pdf},
}

@article{ai4science_microsoft_research_impact_2023,
	title = {The {Impact} of {Large} {Language} {Models} on {Scientific} {Discovery}: a {Preliminary} {Study} using {GPT}-4},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {The {Impact} of {Large} {Language} {Models} on {Scientific} {Discovery}},
	url = {https://arxiv.org/abs/2311.07361},
	doi = {10.48550/ARXIV.2311.07361},
	abstract = {In recent years, groundbreaking advancements in natural language processing have culminated in the emergence of powerful large language models (LLMs), which have showcased remarkable capabilities across a vast array of domains, including the understanding, generation, and translation of natural language, and even tasks that extend beyond language processing. In this report, we delve into the performance of LLMs within the context of scientific discovery, focusing on GPT-4, the state-of-the-art language model. Our investigation spans a diverse range of scientific areas encompassing drug discovery, biology, computational chemistry (density functional theory (DFT) and molecular dynamics (MD)), materials design, and partial differential equations (PDE). Evaluating GPT-4 on scientific tasks is crucial for uncovering its potential across various research domains, validating its domain-specific expertise, accelerating scientific progress, optimizing resource allocation, guiding future model development, and fostering interdisciplinary research. Our exploration methodology primarily consists of expert-driven case assessments, which offer qualitative insights into the model's comprehension of intricate scientific concepts and relationships, and occasionally benchmark testing, which quantitatively evaluates the model's capacity to solve well-defined domain-specific problems. Our preliminary exploration indicates that GPT-4 exhibits promising potential for a variety of scientific applications, demonstrating its aptitude for handling complex problem-solving and knowledge integration tasks. Broadly speaking, we evaluate GPT-4's knowledge base, scientific understanding, scientific numerical calculation abilities, and various scientific prediction capabilities.},
	urldate = {2023-12-19},
	author = {AI4Science Microsoft Research and Quantum Microsoft Azure},
	year = {2023},
	note = {Publisher: arXiv
Version Number: 2},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, Artificial Intelligence (cs.AI)},
	annote = {Other
230 pages report; 181 pages for main contents},
	file = {Полный текст:C\:\\Users\\User\\Zotero\\storage\\Q5NC7M3V\\AI4Science и Quantum - 2023 - The Impact of Large Language Models on Scientific .pdf:application/pdf},
}

@article{romera-paredes_mathematical_2023,
	title = {Mathematical discoveries from program search with large language models},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/s41586-023-06924-6},
	doi = {10.1038/s41586-023-06924-6},
	language = {en},
	urldate = {2023-12-26},
	journal = {Nature},
	author = {Romera-Paredes, Bernardino and Barekatain, Mohammadamin and Novikov, Alexander and Balog, Matej and Kumar, M. Pawan and Dupont, Emilien and Ruiz, Francisco J. R. and Ellenberg, Jordan S. and Wang, Pengming and Fawzi, Omar and Kohli, Pushmeet and Fawzi, Alhussein},
	month = dec,
	year = {2023},
	file = {Полный текст:C\:\\Users\\User\\Zotero\\storage\\I2SMKCTI\\Romera-Paredes и др. - 2023 - Mathematical discoveries from program search with .pdf:application/pdf},
}

@book{__2004,
	address = {М.},
	title = {Моделирование процессов мышления  в р-адических системах координат.},
	isbn = {5-9221-0501-9},
	publisher = {ФИЗМАТЛИТ},
	author = {Хренников, А. Ю.},
	year = {2004},
	file = {Хренников_Мышление.djvu:C\:\\Users\\User\\Desktop\\Чтение\\Хренников_Мышление.djvu:application/octet-stream},
}

@misc{__2022,
	title = {Знакомство с p-адическими числами. Часть 2, практическая},
	url = {https://habr.com/ru/articles/646143/},
	author = {Самойленко, Сергей},
	month = jan,
	year = {2022},
}


@book{oregan_brief_2021,
	address = {Cham},
	edition = {3rd edition},
	title = {A brief history of computing},
	isbn = {978-3-030-66598-2},
	url = {http://www.worldcat.org/oclc/1264262917},
	publisher = {Springer},
	author = {O'Regan, Gerard},
	year = {2021},
	keywords = {Computer, COMPUTERS, Datenverarbeitung, Ordinateurs, Geschichte, Geschiedenis, Informatica, Informatique - Industrie - Histoire, Ordinateurs - Histoire, Software},
}

@misc{noauthor__nodate,
	title = {Научное открытие},
	url = {https://brickofknowledge.com/articles/scientific-discovery},
	abstract = {Научное открытие — это процесс или результат успешного научного исследования. Объектами открытия могут быть вещи, события, процессы, причины и качества.},
	language = {en},
	urldate = {2024-05-16},
	journal = {Brick of Knowledge},
	file = {1.pdf:C\:\\Users\\Пользователь\\Downloads\\1.pdf:application/pdf;Snapshot:files/1497/scientific-discovery.html:text/html},
}

@incollection{schickore_scientific_2020,
	edition = {Fall 2020},
	title = {Scientific {Discovery}},
	url = {https://plato.stanford.edu/archives/fall2020/entries/scientific-discovery/},
	booktitle = {The {Stanford} {Encyclopedia} of {Philosophy}},
	publisher = {Metaphysics Research Lab, Stanford University},
	author = {Schickore, Jutta},
	editor = {Zalta, Edward N. and Nodelman, Uri},
	year = {2020},
}

@misc{ai4science_microsoft_research_impact_2023,
	title = {The {Impact} of {Large} {Language} {Models} on {Scientific} {Discovery}: a {Preliminary} {Study} using {GPT}-4},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2311.07361},
	abstract = {In recent years, groundbreaking advancements in natural language processing have culminated in the emergence of powerful large language models (LLMs), which have showcased remarkable capabilities across a vast array of domains, including the understanding, generation, and translation of natural language, and even tasks that extend beyond language processing. In this report, we delve into the performance of LLMs within the context of scientific discovery, focusing on GPT-4, the state-of-the-art language model. Our investigation spans a diverse range of scientific areas encompassing drug discovery, biology, computational chemistry (density functional theory (DFT) and molecular dynamics (MD)), materials design, and partial differential equations (PDE). Evaluating GPT-4 on scientific tasks is crucial for uncovering its potential across various research domains, validating its domain-specific expertise, accelerating scientific progress, optimizing resource allocation, guiding future model development, and fostering interdisciplinary research. Our exploration methodology primarily consists of expert-driven case assessments, which offer qualitative insights into the model's comprehension of intricate scientific concepts and relationships, and occasionally benchmark testing, which quantitatively evaluates the model's capacity to solve well-defined domain-specific problems. Our preliminary exploration indicates that GPT-4 exhibits promising potential for a variety of scientific applications, demonstrating its aptitude for handling complex problem-solving and knowledge integration tasks. Broadly speaking, we evaluate GPT-4's knowledge base, scientific understanding, scientific numerical calculation abilities, and various scientific prediction capabilities.},
	urldate = {2024-05-16},
	journal = {https://arxiv.org},
	author = {AI4Science. Microsoft Research and Quantum, Microsoft Azure},
	year = {2023},
	note = {Publisher: [object Object]
Version Number: 2},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, Artificial Intelligence (cs.AI)},
	annote = {Other
230 pages report; 181 pages for main contents},
	file = {Полный текст:files/1498/AI4Science и Quantum - 2023 - The Impact of Large Language Models on Scientific .pdf:application/pdf},
}

@article{schick_toolformer_2023,
	title = {Toolformer: {Language} {Models} {Can} {Teach} {Themselves} to {Use} {Tools}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {Toolformer},
	url = {https://arxiv.org/abs/2302.04761},
	doi = {10.48550/ARXIV.2302.04761},
	abstract = {Language models (LMs) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale. They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller models excel. In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction. This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each API. We incorporate a range of tools, including a calculator, a Q{\textbackslash}\&amp;A system, two different search engines, a translation system, and a calendar. Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities.},
	urldate = {2024-05-16},
	author = {Schick, Timo and Dwivedi-Yu, Jane and Dessì, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
	year = {2023},
	note = {Publisher: [object Object]
Version Number: 1},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences},
	file = {Полный текст:files/1500/Schick и др. - 2023 - Toolformer Language Models Can Teach Themselves t.pdf:application/pdf},
}

@article{castelvecchi_deepmind_2024,
	title = {{DeepMind} {AI} outdoes human mathematicians on unsolved problem},
	volume = {625},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/d41586-023-04043-w},
	doi = {10.1038/d41586-023-04043-w},
	language = {en},
	number = {7993},
	urldate = {2024-05-16},
	journal = {Nature},
	author = {Castelvecchi, Davide},
	month = jan,
	year = {2024},
	pages = {12--13},
}

@article{romera-paredes_mathematical_2024,
	title = {Mathematical discoveries from program search with large language models},
	volume = {625},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/s41586-023-06924-6},
	doi = {10.1038/s41586-023-06924-6},
	abstract = {Abstract
            
              Large language models (LLMs) have demonstrated tremendous capabilities in solving complex tasks, from quantitative reasoning to understanding natural language. However, LLMs sometimes suffer from confabulations (or hallucinations), which can result in them making plausible but incorrect statements
              1,2
              . This hinders the use of current large models in scientific discovery. Here we introduce FunSearch (short for searching in the function space), an evolutionary procedure based on pairing a pretrained LLM with a systematic evaluator. We demonstrate the effectiveness of this approach to surpass the best-known results in important problems, pushing the boundary of existing LLM-based approaches
              3
              . Applying FunSearch to a central problem in extremal combinatorics—the cap set problem—we discover new constructions of large cap sets going beyond the best-known ones, both in finite dimensional and asymptotic cases. This shows that it is possible to make discoveries for established open problems using LLMs. We showcase the generality of FunSearch by applying it to an algorithmic problem, online bin packing, finding new heuristics that improve on widely used baselines. In contrast to most computer search approaches, FunSearch searches for programs that describe how to solve a problem, rather than what the solution is. Beyond being an effective and scalable strategy, discovered programs tend to be more interpretable than raw solutions, enabling feedback loops between domain experts and FunSearch, and the deployment of such programs in real-world applications.},
	language = {en},
	number = {7995},
	urldate = {2024-05-16},
	journal = {Nature},
	author = {Romera-Paredes, Bernardino and Barekatain, Mohammadamin and Novikov, Alexander and Balog, Matej and Kumar, M. Pawan and Dupont, Emilien and Ruiz, Francisco J. R. and Ellenberg, Jordan S. and Wang, Pengming and Fawzi, Omar and Kohli, Pushmeet and Fawzi, Alhussein},
	month = jan,
	year = {2024},
	pages = {468--475},
	file = {Полный текст:files/1502/Romera-Paredes и др. - 2024 - Mathematical discoveries from program search with .pdf:application/pdf},
}

@article{__2007,
	title = {Эпистемология и стратегия научного поиска},
	volume = {2},
	url = {https://www.sie-journal.ru/epistemologiya-i-strategiya-nauchnogo-poiska},
	number = {1},
	journal = {Управление наукой и наукометрия},
	author = {Плюснин, Ю. М.},
	year = {2007},
	note = {https://www.sie-journal.ru/assets/uploads/issues/2007/4aebc2c2fbf9481c06eb3036d6d35ea5.pdf},
	pages = {74--95},
}

@book{pool_ai_2024,
	address = {Washington, D.C.},
	edition = {Science and Engineering Capacity Development Unit, Computer Science and Telecommunications Board, Policy and Global Affairs, Division on Engineering and Physical Sciences, National Academies of Sciences, Engineering, and Medicine},
	title = {{AI} for {Scientific} {Discovery}: {Proceedings} of a {Workshop}},
	isbn = {978-0-309-71497-6},
	shorttitle = {{AI} for {Scientific} {Discovery}},
	url = {https://www.nap.edu/catalog/27457},
	urldate = {2024-05-24},
	publisher = {National Academies Press},
	editor = {Pool, Robert},
	month = apr,
	year = {2024},
	doi = {10.17226/27457},
	note = {Pages: 27457},
	file = {Bookshelf_NBK603474.pdf:C\:\\Users\\User\\Downloads\\Bookshelf_NBK603474.pdf:application/pdf},
}

@article{hinsen_computational_2014,
	title = {Computational science: shifting the focus from tools to models},
	volume = {3},
	issn = {2046-1402},
	shorttitle = {Computational science},
	url = {https://f1000research.com/articles/3-101/v2},
	doi = {10.12688/f1000research.3978.2},
	abstract = {Computational techniques have revolutionized many aspects of scientific research over the last few decades. Experimentalists use computation for data analysis, processing ever bigger data sets. Theoreticians compute predictions from ever more complex models. However, traditional articles do not permit the publication of big data sets or complex models. As a consequence, these crucial pieces of information no longer enter the scientific record. Moreover, they have become prisoners of scientific software: many models exist only as software implementations, and the data are often stored in proprietary formats defined by the software. In this article, I argue that this emphasis on software tools over models and data is detrimental to science in the long term, and I propose a means by which this can be reversed.},
	language = {en},
	urldate = {2024-05-24},
	journal = {F1000Research},
	author = {Hinsen, Konrad},
	month = jun,
	year = {2014},
	pages = {101},
	file = {Полный текст:files/1578/Hinsen - 2014 - Computational science shifting the focus from too.pdf:application/pdf},
}

@article{birhane_science_2023,
	title = {Science in the age of large language models},
	volume = {5},
	issn = {2522-5820},
	url = {https://www.nature.com/articles/s42254-023-00581-4},
	doi = {10.1038/s42254-023-00581-4},
	language = {en},
	number = {5},
	urldate = {2024-05-28},
	journal = {Nature Reviews Physics},
	author = {Birhane, Abeba and Kasirzadeh, Atoosa and Leslie, David and Wachter, Sandra},
	month = apr,
	year = {2023},
	pages = {277--280},
	file = {Полный текст:files/1591/Birhane и др. - 2023 - Science in the age of large language models.pdf:application/pdf},
}

@article{krenn_scientific_2022,
	title = {On scientific understanding with artificial intelligence},
	volume = {4},
	issn = {2522-5820},
	url = {https://doi.org/10.1038/s42254-022-00518-3},
	doi = {10.1038/s42254-022-00518-3},
	abstract = {An oracle that correctly predicts the outcome of every particle physics experiment, the products of every possible chemical reaction or the function of every protein would revolutionize science and technology. However, scientists would not be entirely satisfied because they would want to comprehend how the oracle made these predictions. This is scientific understanding, one of the main aims of science. With the increase in the available computational power and advances in artificial intelligence, a natural question arises: how can advanced computational systems, and specifically artificial intelligence, contribute to new scientific understanding or gain it autonomously? Trying to answer this question, we adopted a definition of ‘scientific understanding’ from the philosophy of science that enabled us to overview the scattered literature on the topic and, combined with dozens of anecdotes from scientists, map out three dimensions of computer-assisted scientific understanding. For each dimension, we review the existing state of the art and discuss future developments. We hope that this Perspective will inspire and focus research directions in this multidisciplinary emerging field.},
	number = {12},
	journal = {Nature Reviews Physics},
	author = {Krenn, Mario and Pollice, Robert and Guo, Si Yue and Aldeghi, Matteo and Cervera-Lierta, Alba and Friederich, Pascal and dos Passos Gomes, Gabriel and Häse, Florian and Jinich, Adrian and Nigam, AkshatKumar and Yao, Zhenpeng and Aspuru-Guzik, Alán},
	month = dec,
	year = {2022},
	pages = {761--769},
	file = {Полный текст:files/1590/Krenn и др. - 2022 - On scientific understanding with artificial intell.pdf:application/pdf},
}

@incollection{muller_computational_2016,
	address = {Cham},
	title = {Computational {Scientific} {Discovery} and {Cognitive} {Science} {Theories}},
	volume = {375},
	isbn = {978-3-319-23290-4 978-3-319-23291-1},
	url = {https://link.springer.com/10.1007/978-3-319-23291-1_6},
	language = {en},
	urldate = {2024-05-25},
	booktitle = {Computing and {Philosophy}},
	publisher = {Springer International Publishing},
	author = {Addis, Mark and Sozou, Peter D. and Lane, Peter C. and Gobet, Fernand},
	editor = {Müller, Vincent C.},
	year = {2016},
	doi = {10.1007/978-3-319-23291-1_6},
	note = {Series Title: Synthese Library},
	pages = {83--97},
	file = {ComputationalScientificDiscoveryAddisetal.final.pdf:C\:\\Users\\Пользователь\\Downloads\\ComputationalScientificDiscoveryAddisetal.final.pdf:application/pdf},
}

@book{boden_creative_2004,
	address = {London ; New York},
	edition = {2nd ed},
	title = {The creative mind: myths and mechanisms},
	isbn = {978-0-415-31452-7 978-0-415-31453-4},
	shorttitle = {The creative mind},
	url = {https://www.tribuneschoolchd.com/uploads/tms/files/1595167242-the-creative-mind-pdfdrive-com-.pdf},
	publisher = {Routledge},
	author = {Boden, Margaret A.},
	year = {2004},
	keywords = {Artificial intelligence, Creative ability},
}

@article{community_sunpypython_2015,
	title = {{SunPy}—{Python} for solar physics},
	volume = {8},
	issn = {1749-4699},
	url = {https://iopscience.iop.org/article/10.1088/1749-4699/8/1/014009},
	doi = {10.1088/1749-4699/8/1/014009},
	number = {1},
	urldate = {2024-05-25},
	journal = {Computational Science \& Discovery},
	author = {Community, The SunPy and Mumford, Stuart J and Christe, Steven and Pérez-Suárez, David and Ireland, Jack and Shih, Albert Y and Inglis, Andrew R and Liedtke, Simon and Hewett, Russell J and Mayer, Florian and Hughitt, Keith and Freij, Nabil and Meszaros, Tomas and Bennett, Samuel M and Malocha, Michael and Evans, John and Agrawal, Ankit and Leonard, Andrew J and Robitaille, Thomas P and Mampaey, Benjamin and Campos-Rozo, Jose Iván and Kirk, Michael S},
	month = jul,
	year = {2015},
	pages = {014009},
	file = {Полный текст:files/1594/Community и др. - 2015 - SunPy—Python for solar physics.pdf:application/pdf},
}

@article{nickles_truth_1988,
	title = {Truth or {Consequences}? {Generative} versus {Consequential} {Justification} in {Science}},
	volume = {1988},
	issn = {02708647},
	url = {http://www.jstor.org/stable/192900},
	abstract = {[Pure consequentialists hold that all theoretical justification derives from testing the consequences of hypotheses, while generativists maintain that reasoning (some feature of) the hypothesis from we already know is an important form of justification. The strongest form of justification (they claim) is an idealized discovery argument. In the guise of H-D methodology, consequentialism is widely supposed to have defeated generativism during the 19th century. I argue that novel prediction fails to overcome the logical weakness of consequentialism or to render generative methodology superfluous. Specifically, Bayesian consequentialism is not an alternative to generativism but reduces to an instance of it.]},
	urldate = {2024-05-24},
	journal = {PSA: Proceedings of the Biennial Meeting of the Philosophy of Science Association},
	author = {Nickles, Thomas},
	year = {1988},
	note = {Publisher: [University of Chicago Press, Springer, Philosophy of Science Association]},
	pages = {393--405},
}

@article{niszczota_judgments_2023,
	title = {Judgments of {Research} {Co}-{Created} by {Generative} {AI}: {Experimental} {Evidence}},
	issn = {1556-5068},
	shorttitle = {Judgments of {Research} {Co}-{Created} by {Generative} {AI}},
	url = {https://www.ssrn.com/abstract=4443934},
	doi = {10.2139/ssrn.4443934},
	language = {en},
	urldate = {2024-05-24},
	journal = {SSRN Electronic Journal},
	author = {Niszczota, Paweł and Conway, Paul},
	year = {2023},
	file = {Отправленная версия:files/1596/Niszczota и Conway - 2023 - Judgments of Research Co-Created by Generative AI.pdf:application/pdf},
}

@incollection{muntean_computation_2014,
	title = {Computation and {Scientific} {Discovery}? {A} {Bio}-{Inspired} {Approach}},
	url = {http://philsci-archive.pitt.edu/11124/1/2014_03_digital_guesswork_ver_4_submitted_to_ALIFE14.pdf},
	booktitle = {Artificial {Life} 14. {Proceedings} of the {Fourteenth} {International} {Conference} on the {Synthesis} and {Simulation} of {Living} {Systems}},
	author = {Muntean, Ioan},
	editor = {Sayama, Hiroki},
	year = {2014},
}

@book{kuppers_computability_2018,
	address = {Cham},
	edition = {1st ed. 2018},
	series = {The {Frontiers} {Collection}},
	title = {The {Computability} of the {World}: {How} {Far} {Can} {Science} {Take} {Us}?},
	isbn = {978-3-319-67369-1},
	shorttitle = {The {Computability} of the {World}},
	abstract = {In this thought-provoking book Küppers, an internationally renowned physicist, philosopher and theoretical biologist, addresses a number of science's deepest questions: Can physics advance to the origin of all things and explain the unique phenomena of life, time and history? Are there unsolvable enigmas of the world? How did life originate? Is language a general phenomenon of Nature? What is time? Is it possible to express the history of the world in formulae? Where is science leading us? These and other provocative questions essential for a deeper understanding of the world are treated here in a refreshing and stimulating manner},
	publisher = {Springer International Publishing : Imprint: Springer},
	author = {Küppers, Bernd-Olaf},
	year = {2018},
	doi = {10.1007/978-3-319-67369-1},
	keywords = {Physics, Complex Systems, Dynamical systems, History and Philosophical Foundations of Physics, Life sciences, Philosophy of nature, Philosophy of Nature, Popular Life Sciences, Popular Science in Physics, Statistical physics, Statistical Physics and Dynamical Systems},
	annote = {Is an absolute knowledge of the world possible? -- Are there unsolvable world enigmas? -- How could life have originated? -- What is information? -- Is language a general principle of nature? -- Can the beauty of Nature be objectified? -- What is time? -- Can history be condensed into formulae? -- Where is science going?},
	file = {Отправленная версия:files/1597/Küppers - 2018 - The Computability of the World How Far Can Scienc.pdf:application/pdf},
}

@book{noauthor_computability_2017,
	address = {New York, NY},
	title = {The computability of the world},
	isbn = {978-3-319-67367-7},
	publisher = {Springer Berlin Heidelberg},
	year = {2017},
}

@misc{noauthor_funsearch_2023,
	title = {{FunSearch}: {Making} new discoveries in mathematical sciences using {Large} {Language} {Models}},
	shorttitle = {{FunSearch}},
	url = {https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/},
	abstract = {We introduce FunSearch, a method for searching for “functions” written in computer code, and find new solutions in mathematics and computer science. FunSearch works by pairing a pre-trained LLM,...},
	language = {en},
	urldate = {2024-05-28},
	journal = {Google DeepMind},
	month = dec,
	year = {2023},
	file = {Snapshot:files/1614/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models.html:text/html},
}

@misc{noauthor_muzero_2023,
	title = {{MuZero}, {AlphaZero}, and {AlphaDev}: {Optimizing} computer systems},
	shorttitle = {{MuZero}, {AlphaZero}, and {AlphaDev}},
	url = {https://deepmind.google/impact/optimizing-computer-systems-with-more-generalized-ai-tools/},
	abstract = {As part of our aim to build increasingly capable and general artificial intelligence (AI) systems, we’re working to create AI tools with a broader understanding of the world. This can allow useful...},
	language = {en},
	urldate = {2024-05-28},
	journal = {Google DeepMind},
	month = jun,
	year = {2023},
	file = {Snapshot:files/1616/optimizing-computer-systems-with-more-generalized-ai-tools.html:text/html},
}

@misc{noauthor_httpswwwelasticcowhat-islarge-language-models_nodate,
	title = {https://www.elastic.co/what-is/large-language-models},
	url = {https://www.elastic.co/what-is/large-language-models},
	urldate = {2024-05-28},
	file = {https\://www.elastic.co/what-is/large-language-models:files/1619/large-language-models.html:text/html},
}

@misc{noauthor_what_nodate,
	title = {What is a large language model ({LLM})?},
	url = {https://www.elastic.co/what-is/large-language-models},
	urldate = {2024-05-28},
	file = {https\://www.elastic.co/what-is/large-language-models:files/1620/large-language-models.html:text/html},
}

@article{__2013,
	title = {Биоинформатика: метод во главе угла},
	volume = {1},
	number = {49},
	journal = {Наука из первых рук},
	author = {Афонников, Д. А. and Иваниенко, В. А.},
	year = {2013},
	pages = {50--59},
}

@book{floridi_blackwell_2004,
	address = {Malden, Mass.},
	edition = {1. publ},
	series = {Blackwell philosophy guides},
	title = {The {Blackwell} guide to the philosophy of computing and information},
	isbn = {978-0-631-22918-6 978-0-631-22919-3},
	language = {eng},
	number = {14},
	publisher = {Blackwell},
	editor = {Floridi, Luciano},
	year = {2004},
	annote = {Parallel als digitalisierte Ausg. erschienen Includes bibliographical references and index},
	file = {Table of Contents PDF:files/1633/Floridi - 2004 - The Blackwell guide to the philosophy of computing.pdf:application/pdf},
}

@incollection{floridi_computing_2004,
	address = {Malden, Mass.},
	edition = {1. publ},
	series = {Blackwell philosophy guides},
	title = {Computing in the {Philosophy} of {Science}},
	isbn = {978-0-631-22918-6 978-0-631-22919-3},
	language = {eng},
	number = {14},
	booktitle = {The {Blackwell} guide to the philosophy of computing and information},
	publisher = {Blackwell},
	author = {Thagard, Paul},
	editor = {Floridi, Luciano},
	year = {2004},
	pages = {307--317},
}

@misc{noauthor_gpt-like_2023,
	title = {{GPT}-like модель «впервые сделала научное открытие»: что, как, и куда дальше?},
	shorttitle = {{GPT}-like модель «впервые сделала научное открытие»},
	url = {https://habr.com/ru/companies/ods/articles/781138/},
	abstract = {14-го декабря в одном из самых авторитетных общенаучных журналов Nature была опубликована статья с, кажется, сенсационным заголовком: «ИИ-модели Google DeepMind превосходят математиков в решении...},
	language = {ru},
	urldate = {2024-06-10},
	journal = {Хабр},
	month = dec,
	year = {2023},
	file = {Snapshot:files/1636/781138.html:text/html},
}

@article{fawzi_discovering_2022,
	title = {Discovering faster matrix multiplication algorithms with reinforcement learning},
	volume = {610},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/s41586-022-05172-4},
	doi = {10.1038/s41586-022-05172-4},
	abstract = {Abstract
            
              Improving the efficiency of algorithms for fundamental computations can have a widespread impact, as it can affect the overall speed of a large amount of computations. Matrix multiplication is one such primitive task, occurring in many systems—from neural networks to scientific computing routines. The automatic discovery of algorithms using machine learning offers the prospect of reaching beyond human intuition and outperforming the current best human-designed algorithms. However, automating the algorithm discovery procedure is intricate, as the space of possible algorithms is enormous. Here we report a deep reinforcement learning approach based on AlphaZero
              1
              for discovering efficient and provably correct algorithms for the multiplication of arbitrary matrices. Our agent, AlphaTensor, is trained to play a single-player game where the objective is finding tensor decompositions within a finite factor space. AlphaTensor discovered algorithms that outperform the state-of-the-art complexity for many matrix sizes. Particularly relevant is the case of 4 × 4 matrices in a finite field, where AlphaTensor’s algorithm improves on Strassen’s two-level algorithm for the first time, to our knowledge, since its discovery 50 years ago
              2
              . We further showcase the flexibility of AlphaTensor through different use-cases: algorithms with state-of-the-art complexity for structured matrix multiplication and improved practical efficiency by optimizing matrix multiplication for runtime on specific hardware. Our results highlight AlphaTensor’s ability to accelerate the process of algorithmic discovery on a range of problems, and to optimize for different criteria.},
	language = {en},
	number = {7930},
	urldate = {2024-06-10},
	journal = {Nature},
	author = {Fawzi, Alhussein and Balog, Matej and Huang, Aja and Hubert, Thomas and Romera-Paredes, Bernardino and Barekatain, Mohammadamin and Novikov, Alexander and R. Ruiz, Francisco J. and Schrittwieser, Julian and Swirszcz, Grzegorz and Silver, David and Hassabis, Demis and Kohli, Pushmeet},
	month = oct,
	year = {2022},
	pages = {47--53},
}

@article{hope_computational_2023,
	title = {A {Computational} {Inflection} for {Scientific} {Discovery}},
	volume = {66},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3576896},
	doi = {10.1145/3576896},
	abstract = {Enabling researchers to leverage systems to overcome the limits of human cognitive capacity.},
	language = {en},
	number = {8},
	urldate = {2024-06-17},
	journal = {Communications of the ACM},
	author = {Hope, Tom and Downey, Doug and Weld, Daniel S. and Etzioni, Oren and Horvitz, Eric},
	month = aug,
	year = {2023},
	pages = {62--73},
	file = {3576896.pdf:C\:\\Users\\User\\Downloads\\3576896.pdf:application/pdf},
}

@incollection{magnani_computational_2017,
	address = {Cham},
	title = {Computational {Scientific} {Discovery}},
	isbn = {978-3-319-30525-7 978-3-319-30526-4},
	url = {http://link.springer.com/10.1007/978-3-319-30526-4_33},
	language = {en},
	urldate = {2024-06-17},
	booktitle = {Springer {Handbook} of {Model}-{Based} {Science}},
	publisher = {Springer International Publishing},
	author = {Sozou, Peter D. and Lane, Peter C.R. and Addis, Mark and Gobet, Fernand},
	editor = {Magnani, Lorenzo and Bertolotti, Tommaso},
	year = {2017},
	doi = {10.1007/978-3-319-30526-4_33},
	pages = {719--734},
	file = {Computationalscientifictheory.pdf:C\:\\Users\\User\\Downloads\\Computationalscientifictheory.pdf:application/pdf},
}

@inproceedings{park_generative_2023,
	address = {San Francisco CA USA},
	title = {Generative {Agents}: {Interactive} {Simulacra} of {Human} {Behavior}},
	isbn = {9798400701320},
	shorttitle = {Generative {Agents}},
	url = {https://dl.acm.org/doi/10.1145/3586183.3606763},
	doi = {10.1145/3586183.3606763},
	language = {en},
	urldate = {2024-06-19},
	booktitle = {Proceedings of the 36th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
	month = oct,
	year = {2023},
	pages = {1--22},
	file = {Полный текст:files/1665/Park и др. - 2023 - Generative Agents Interactive Simulacra of Human .pdf:application/pdf},
}

